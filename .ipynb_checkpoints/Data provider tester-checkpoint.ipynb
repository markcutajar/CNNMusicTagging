{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data provider unit testing\n",
    "\n",
    "The aim of this notebook is to create a mock dataset with random numbers and random targets and test the data provider to produce a queue of tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pydst.rate_limiters import RateLimited \n",
    "from pydst.dataproviders import DataProvider\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating mock dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate data\n",
    "tmp = np.arange(0, 512)\n",
    "data = np.column_stack((tmp,tmp,tmp,tmp))\n",
    "\n",
    "# Generate targets\n",
    "targets=[]\n",
    "for num in [int(i) for i in tmp]:\n",
    "    tmp_tgt = [int(i) for i in list(np.binary_repr(num))]\n",
    "    if len(tmp_tgt) != 9:\n",
    "        remain = 9 - len(tmp_tgt)\n",
    "        zeros = [0]*remain\n",
    "        zeros.extend(tmp_tgt)\n",
    "        tmp_tgt = zeros\n",
    "    targets.append(tmp_tgt)\n",
    "targets = np.asarray(targets)\n",
    "tids = np.asarray(tmp)\n",
    "\n",
    "# Print sizes\n",
    "print('Data shape: ' + str(data.shape))\n",
    "print('Targets shape: ' + str(targets.shape))\n",
    "print('TIDs shape: ' + str(tids.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save data\n",
    "for idx, name in enumerate(tids):\n",
    "    filename = '../mockdataset/data1/train/' + str(name) + '.npy'\n",
    "    row = data[idx, :]\n",
    "    np.save(filename, row)\n",
    "    \n",
    "# Save metadata\n",
    "filename = '../mockdataset/data1/train_metadata.npy'\n",
    "metadata = {'targets': targets, 'tids': tids}\n",
    "np.save(filename, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Testing the data provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Thread(Thread-4, started daemon 139863345043200)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"pydst/dataproviders.py\", line 167, in load_q\n",
      "    sess.run(self.enqop, feed_dict={self.q_din: cdata, self.q_tin: ctargets})\n",
      "  File \"/home/mark/.virtualenvs/dst/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 778, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/home/mark/.virtualenvs/dst/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 933, in _run\n",
      "    + e.args[0])\n",
      "TypeError: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder:0\", shape=(10, 4), dtype=float32) is not an element of this graph.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with tf.device('/cpu:0'):\n",
    "    trainData = DataProvider(graph=graph, which_set='train', batch_size=10, down_sample=1, target_size=6)\n",
    "    data_batch, targets_batch = trainData.get_data()\n",
    "\n",
    "# >> DEFINE MODEL HERE    \n",
    "with graph.as_default():    \n",
    "    sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=8))\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    trainData.enable(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 435.  435.  435.  435.]\n",
      " [ 271.  271.  271.  271.]\n",
      " [ 396.  396.  396.  396.]\n",
      " [  96.   96.   96.   96.]\n",
      " [ 280.  280.  280.  280.]\n",
      " [ 399.  399.  399.  399.]\n",
      " [  90.   90.   90.   90.]\n",
      " [ 135.  135.  135.  135.]\n",
      " [ 329.  329.  329.  329.]\n",
      " [ 132.  132.  132.  132.]]\n",
      "[[ 463.  463.  463.  463.]\n",
      " [ 103.  103.  103.  103.]\n",
      " [  41.   41.   41.   41.]\n",
      " [  24.   24.   24.   24.]\n",
      " [  54.   54.   54.   54.]\n",
      " [ 338.  338.  338.  338.]\n",
      " [ 377.  377.  377.  377.]\n",
      " [ 233.  233.  233.  233.]\n",
      " [ 291.  291.  291.  291.]\n",
      " [ 223.  223.  223.  223.]]\n",
      "[[   2.    2.    2.    2.]\n",
      " [  13.   13.   13.   13.]\n",
      " [ 393.  393.  393.  393.]\n",
      " [ 363.  363.  363.  363.]\n",
      " [ 507.  507.  507.  507.]\n",
      " [ 353.  353.  353.  353.]\n",
      " [ 472.  472.  472.  472.]\n",
      " [ 480.  480.  480.  480.]\n",
      " [ 265.  265.  265.  265.]\n",
      " [ 249.  249.  249.  249.]]\n",
      "[[  87.   87.   87.   87.]\n",
      " [  89.   89.   89.   89.]\n",
      " [ 406.  406.  406.  406.]\n",
      " [  28.   28.   28.   28.]\n",
      " [ 342.  342.  342.  342.]\n",
      " [  70.   70.   70.   70.]\n",
      " [ 411.  411.  411.  411.]\n",
      " [ 510.  510.  510.  510.]\n",
      " [ 330.  330.  330.  330.]\n",
      " [ 313.  313.  313.  313.]]\n",
      "[[ 395.  395.  395.  395.]\n",
      " [ 442.  442.  442.  442.]\n",
      " [ 199.  199.  199.  199.]\n",
      " [  46.   46.   46.   46.]\n",
      " [ 431.  431.  431.  431.]\n",
      " [ 352.  352.  352.  352.]\n",
      " [ 415.  415.  415.  415.]\n",
      " [ 356.  356.  356.  356.]\n",
      " [ 506.  506.  506.  506.]\n",
      " [ 183.  183.  183.  183.]]\n"
     ]
    }
   ],
   "source": [
    "@RateLimited(1)\n",
    "def eval_tensor(sess):\n",
    "    [b,t] = sess.run([data_batch, targets_batch])\n",
    "    print(b)\n",
    "    \n",
    "for num in range(5):\n",
    "    eval_tensor(sess)\n",
    "trainData.disable(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
