{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud ML Engine Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will go over the steps in order ot setup the cloud, some tutorials and how to submit your own trainer and job.\n",
    "\n",
    "Please note these notes mostly follow the https://cloud.google.com/ml-engine/docs/how-tos/ with some additional material. These guides go into detail on some of the concepts.\n",
    "\n",
    "\n",
    "Development considerations: https://cloud.google.com/ml-engine/docs/concepts/environment-overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up the Cloud SDK\n",
    "\n",
    "The first step involves setting up the cloud SDK. Depending on the machine (Mac, Linux or Windows) this can be downloaded from https://cloud.google.com/sdk/. \n",
    "\n",
    "Please note that gcloud, python 2.7 is required. However, tensorflow on Windows requires python 3.5. Therefore, the environment should have this python version configured. Please note that if the newer python 3.6 is used, this produces an incompatible wheel error when installing tensorflow. One could develop code which is possible to run on both pyhton 2.7 and python 3.5.\n",
    "\n",
    "Please note an alternative is to use the Cloud shell on the Google Cloud Platform which has the preinstalled SDK. However, this has limited cababilities such as a limited 5GB space. Other options include setting up and working on a VM in the cloud but that would bt at a cost.\n",
    "\n",
    "Once the SDK has been setup three steps follow.\n",
    "\n",
    "1. Initializing gcloud\n",
    "2. Installing tensorflow\n",
    "3. Authentication\n",
    "4. Test tensorflow\n",
    "\n",
    "How to do these steps can be found on https://cloud.google.com/ml-engine/docs/quickstarts/command-line.\n",
    "\n",
    "Explain that Ubuntu on Bash is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training a sample dataset\n",
    "\n",
    "The dataset considered is the United Status Census Income dataset. The task here involves constructing a model to predict the income catagory. The tutorial is found https://cloud.google.com/ml-engine/docs/how-tos/getting-started-training-prediction. \n",
    "\n",
    "The task here is not the construction of the model. The model is already prebuilt and provided by DNNCombinedLinearClassifier class. Here, the point is getting used to jobs in the cloud. Therefore, we are only augmenting the dataset innputs using a linear or DNN model.\n",
    "\n",
    "As explained in the tutorial, this step will show you how to:\n",
    "\n",
    "1. Create a tensorflow trainer and validate it locally.\n",
    "2. Run the trainer on a single cloud worker.\n",
    "3. Run it on a cloud distributed system.\n",
    "4. Deploy a model to support prediction.\n",
    "5. Request an online prediction and see the response.\n",
    "6. Request a batch prediction.\n",
    "\n",
    "The dataset files can be found at https://github.com/GoogleCloudPlatform/cloudml-samples/archive/master.zip. These should be downlaoded and extracted. And the current directory chagned to cloudml-samples-master/census/estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trianing data can be copied from the cloud to a *data* folder in the *estimator* directory:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mkdir data\n",
    "gsutil -m cp gs://cloudml-public/census/data/* data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, paths need to be set to these directories:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TRAIN_DATA=$(pwd)/data/adult.data.csv\n",
    "EVAL_DATA=$(pwd)/data/adult.test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Running a local trainer\n",
    "\n",
    "The first step prior to submitting a job to the cloud is to test the job locally. This avoids additinal costs resulting from running hte job multiple times to debug. The cloud ml-engine provides a process where it emulates the cloud and hence is a good testing platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs of the job need to be saved to a specific folder. It is generally good practice that this folder is empty aswell:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MODEL_DIR=output\n",
    "rm -rf $MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the job can be submitted:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gcloud ml-engine local train \\\n",
    "    --module-name trainer.task \\\n",
    "    --package-path trainer/ \\\n",
    "    -- \\\n",
    "    --train-files $TRAIN_DATA \\\n",
    "    --eval-files $EVAL_DATA \\\n",
    "    --train-steps 1000 \\\n",
    "    --job-dir $MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key word *local* denotes that the job is performed on the host and not in the cloud. The module name provides the task localtion and the package path the package location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the output can be visualised using tensorboard:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tensorboard --logdir=$MODEL_DIR --port=6066"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Running a distributed local trainer\n",
    "\n",
    "Similar to the local trainer, the engine provides a process to emulate workers in a distributed fashion. Once again this can be used as a testing platform for the cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new output directory can be specified:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MODEL_DIR=output-dist\n",
    "rm -rf $MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the job in distributed mode can be submitted:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gcloud ml-engine local train \\\n",
    "    --module-name trainer.task \\\n",
    "    --package-path trainer/ \\\n",
    "    --distributed \\\n",
    "    -- \\\n",
    "    --train-files $TRAIN_DATA \\\n",
    "    --eval-files $EVAL_DATA \\\n",
    "    --train-steps 1000 \\\n",
    "    --job-dir $MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arguments here are similar to the single worker local process. However, a key word *--distributed* is added to instruct the engine to perform the job in distributed mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again the output can be found in $MODEL_DIR and can be analysed using tensorboard."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tensorboard --logdir=$MODEL_DIR --port=6066"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Setting up for the Cloud\n",
    "\n",
    "Running the job in the cloud is similar to running locally with some minor differences. One of the differences is that the data needs to be stored in the Google Cloud storage.\n",
    "\n",
    "Hence, a bucket in the same location as that of the set project needs to be created and the data uploaded to the bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the project ID is defined together with a bucket name:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PROJECT_ID=$(gcloud config list project --format \"value(core.project)\")\n",
    "BUCKET_NAME=${PROJECT_ID}-mlengine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The region is specified:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "REGION=us-east1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new bucket is created by:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gsutil mb -l $REGION gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the data can be uploaded to the bucket and the `TRAIN_DATA` and `EVAL_DATA` updated appropriately."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gsutil cp -r data gs://$BUCKET_NAME/data\n",
    "\n",
    "TRAIN_DATA=gs://$BUCKET_NAME/data/adult.data.csv\n",
    "EVAL_DATA=gs://$BUCKET_NAME/data/adult.test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, it is important to upload also the JSON test file with the test data information and a variable `TEST_JSON` set to point at the file."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gsutil cp ../test.json gs://$BUCKET_NAME/data/test.json\n",
    "\n",
    "TEST_JSON=gs://$BUCKET_NAME/data/test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Training a single worker in the cloud\n",
    "\n",
    "Once the files are uploaded to the cloud, a training job can be submitted to the cloud. Please note that now computation is at a cost. One can choose the amont of resouces used depending on the tiers. In this tutorial the `BASIC` tier to avoid expenses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the `TRAIN_DATA`, `EVAL_DATA`, `REGION` and `BUCKET_NAME` variables are still defined from before, the `JOB_NAME` and `OUTPUT_PATH` can be defined. IF you're starting afresh, initialize these variables as they are needed."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "JOB_NAME=census_single_1\n",
    "\n",
    "OUTPUT_PATH=gs://$BUCKET_NAME/$JOB_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the job can be run in the cloud by:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gcloud ml-engine jobs submit training $JOB_NAME \\\n",
    "    --job-dir $OUTPUT_PATH \\\n",
    "    --runtime-version 1.0 \\\n",
    "    --module-name trainer.task \\\n",
    "    --package-path trainer/ \\\n",
    "    --region $REGION \\\n",
    "    -- \\\n",
    "    --train-files $TRAIN_DATA \\\n",
    "    --eval-files $EVAL_DATA \\\n",
    "    --train-steps 1000 \\\n",
    "    --verbosity DEBUG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that this time, there is no local keyword but insteard there is *submit training $JOB_NAME*. The region and runtime-version now need to be specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, the data can be analysed using tensorboard:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tensorboard --logdir=$OUTPUT_PATH --port=6066"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.5 Training in distributed mode in the cloud\n",
    "\n",
    "Training in distributed mode in the cloud is similar to running distributed mode locally with some changes similar to single instance cloud process. Once again a tier needs to be chosen appropriately in order to balance units (time to execute) and cost per unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that according to the scale tier documentation, any tier above `BASIC` is distributed. The only other scale tier with a single worker is `BASIC_GPU` which is a single isntance with a GPU.\n",
    "\n",
    "https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs#scaletier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Each job once again has a name and output path define as:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "JOB_NAME=census_dist_1\n",
    "\n",
    "OUTPUT_PATH=gs://$BUCKET_NAME/$JOB_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Finally, it can be run using:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "gcloud ml-engine jobs submit training $JOB_NAME \\\n",
    "    --job-dir $OUTPUT_PATH \\\n",
    "    --runtime-version 1.0 \\\n",
    "    --module-name trainer.task \\\n",
    "    --package-path trainer/ \\\n",
    "    --region $REGION \\\n",
    "    --scale-tier STANDARD_1 \\\n",
    "    -- \\\n",
    "    --train-files $TRAIN_DATA \\\n",
    "    --eval-files $EVAL_DATA \\\n",
    "    --train-steps 1000 \\\n",
    "    --verbosity DEBUG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In fact, the running command is exactly the same as the single instance but with a scale tier as `STANDARD_1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Again, results can be analysed using tensorbaord:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "tensorboard --logdir=$OUTPUT_PATH --port=6066"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
