{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data provider unit testing\n",
    "\n",
    "The aim of this notebook is to create a mock dataset with random numbers and random targets and test the data provider to produce a queue of tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from pydst.rate_limiters import RateLimited \n",
    "from pydst.dataproviders import DataProvider\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating mock dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate data\n",
    "tmp = np.arange(0, 512)\n",
    "data = np.column_stack((tmp,tmp,tmp,tmp))\n",
    "\n",
    "# Generate targets\n",
    "targets=[]\n",
    "for num in [int(i) for i in tmp]:\n",
    "    tmp_tgt = [int(i) for i in list(np.binary_repr(num))]\n",
    "    if len(tmp_tgt) != 9:\n",
    "        remain = 9 - len(tmp_tgt)\n",
    "        zeros = [0]*remain\n",
    "        zeros.extend(tmp_tgt)\n",
    "        tmp_tgt = zeros\n",
    "    targets.append(tmp_tgt)\n",
    "targets = np.asarray(targets)\n",
    "tids = np.asarray(tmp)\n",
    "\n",
    "# Print sizes\n",
    "print('Data shape: ' + str(data.shape))\n",
    "print('Targets shape: ' + str(targets.shape))\n",
    "print('TIDs shape: ' + str(tids.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save data\n",
    "for idx, name in enumerate(tids):\n",
    "    filename = '../mockdataset/data1/train/' + str(name) + '.npy'\n",
    "    row = data[idx, :]\n",
    "    np.save(filename, row)\n",
    "    \n",
    "# Save metadata\n",
    "filename = '../mockdataset/data1/train_metadata.npy'\n",
    "metadata = {'targets': targets, 'tids': tids}\n",
    "np.save(filename, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Testing the data provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -4107.  -3620.  -2696. ...,   5319.   6507.   3750.]\n",
      " [  3986.   3401.   3281. ...,  -1098.   -690.   -222.]\n",
      " [  -256.   -548.   -695. ...,  -1807.  -1828.  -1844.]\n",
      " ..., \n",
      " [ -1230.  -4719.  -8908. ...,  13152.   8053.   5774.]\n",
      " [  9888.   6360.   1782. ...,   -938.  -5199.  -4040.]\n",
      " [  8650.   9211.   9963. ...,  14559.  14024.  11821.]]\n",
      "(10, 131072)\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with tf.device('/cpu:0'):\n",
    "    trainData = DataProvider(graph=graph, which_set='train', batch_size=10, num_samples=131072, target_size=6, shape='flat')\n",
    "    data_batch, targets_batch = trainData.get_data()\n",
    "\n",
    "# >> DEFINE MODEL HERE    \n",
    "with graph.as_default():    \n",
    "    sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=8))\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    trainData.enable(sess)\n",
    "    \n",
    "@RateLimited(1)\n",
    "def eval_tensor(sess):\n",
    "    [b,t] = sess.run([data_batch, targets_batch])\n",
    "    print(b)\n",
    "    print(b.shape)\n",
    "    \n",
    "for num in range(1):\n",
    "    eval_tensor(sess)\n",
    "trainData.disable(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 15.13716507  15.875       16.25159645 ...,   9.96492481   9.46856022\n",
      "    8.67287636]\n",
      " [ 12.05631447  11.72623444  13.64362526 ...,  11.54877281  10.54208469\n",
      "    8.37839317]\n",
      " [ 13.20380116  16.49135017  16.92581558 ...,  14.54773521  14.48663712\n",
      "   12.5423336 ]\n",
      " ..., \n",
      " [ 12.72415257  15.12538528  13.90313244 ...,  16.61892319  15.52478886\n",
      "   13.71417141]\n",
      " [  9.75028896  10.79287624  10.20362663 ...,  15.46816158  15.126091\n",
      "   13.31380367]\n",
      " [ 11.30250168  12.0936451   11.68301201 ...,  12.02502823  11.75377941\n",
      "   10.69101715]]\n",
      "(10, 40000)\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with tf.device('/cpu:0'):\n",
    "    trainData = DataProvider(graph=graph, which_set='train', batch_size=10, target_size=6, num_samples=1000, max_samples=2911, \n",
    "                             data_depth=40, root='../magnatagatune/dataset/fbank/', shape='flat')\n",
    "    data_batch, targets_batch = trainData.get_data()\n",
    "    \n",
    "# >> DEFINE MODEL HERE    \n",
    "with graph.as_default():    \n",
    "    sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=8))\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    trainData.enable(sess)\n",
    "    \n",
    "@RateLimited(1)\n",
    "def eval_tensor(sess):\n",
    "    [b,t] = sess.run([data_batch, targets_batch])\n",
    "    print(b)\n",
    "    print(b.shape)\n",
    "    \n",
    "for num in range(1):\n",
    "    eval_tensor(sess)\n",
    "trainData.disable(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
